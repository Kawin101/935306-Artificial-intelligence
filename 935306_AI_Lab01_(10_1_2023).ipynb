{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1NTN5G3tZeFVEcPP+T6Mi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kawin101/935306-Artificial-intelligence/blob/main/935306_AI_Lab01_(10_1_2023).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC6pYSSf5y1D",
        "outputId": "ca5307d0-c9fe-41a1-e368-409a7e138ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5phl9Yv48-Ei",
        "outputId": "d65afe10-90fc-467e-a5be-e3244ab125b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP_iScFmBFn4",
        "outputId": "78c6ebab-5efd-48bd-f090-ba45d9d56466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8qRcnG14uh9",
        "outputId": "064fb7bc-f283-465c-c1bd-17d8b29b8839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'AI', 'is', 'fast', 'growing', 'platform', '.']\n",
            "['AI', 'fast', 'growing', 'platform', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk # natural lang. toolkit\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "txt = 'The AI is fast growing platform. It mimic human brain. I LOVE MY JOB. I LIKE MY CATS.'\n",
        "txt1 = 'ฉัน ชื่อ กรีน. แมว ฉัน ชื่อ เมรี่.'\n",
        "sens = sent_tokenize(txt)  # Sentense segmentation\n",
        "sens1 = sent_tokenize(txt1)\n",
        "# print(sens1[1], sens1[0])\n",
        "# print(sens[2], sens[3], sens[0], sens[1])\n",
        "words = word_tokenize(sens[0]) # Word segmentation\n",
        "print(words)\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "#txt_no_stopword = [w for w in words if not w in stopwords]\n",
        "txt_no_stopword = []\n",
        "for w in words:\n",
        "  if w.lower() not in stopwords:\n",
        "    txt_no_stopword.append(w)\n",
        "print(txt_no_stopword)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk # natural lang. toolkit\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "txt = 'The AI is fast growing platform. It mimic human brain. I LOVE MY JOB. I LIKE MY CATS.'\n",
        "sens = sent_tokenize(txt)  # Sentense segmentation\n",
        "# print(sens[2], sens[3], sens[0], sens[1])\n",
        "words = word_tokenize(sens[0]) # Word segmentation\n",
        "print(words)\n",
        "# https://www.educba.com/nltk-pos-tag/\n",
        "word_pos = nltk.pos_tag(words)\n",
        "print(word_pos) # NNS, NNP, NNPS: Proper and plural noun หรือ คำนามเฉพาะ เหมือน ชื่อคน เช่น Peter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-2dtSiFAK8h",
        "outputId": "b17f806e-edd4-4d14-e49f-a2af9ce379a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'AI', 'is', 'fast', 'growing', 'platform', '.']\n",
            "[('The', 'DT'), ('AI', 'NNP'), ('is', 'VBZ'), ('fast', 'JJ'), ('growing', 'VBG'), ('platform', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}